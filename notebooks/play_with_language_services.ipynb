{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "343ed38d-a294-4bcf-9c92-b8dec0d48c42",
   "metadata": {},
   "source": [
    "Copyright 2025 Province of British Columbia\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426ece9f-7aa9-469a-a1b8-240242ac269c",
   "metadata": {},
   "source": [
    "## Access the Language Service API\n",
    "\n",
    "This notebook contains example code to interact with the Language Studio endpoint, once a model has already been trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee86533-e9cd-4154-86ef-4a1062215ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system stuff\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# requests stuff\n",
    "import requests\n",
    "import time\n",
    "\n",
    "# standard stuff\n",
    "import pandas as pd\n",
    "\n",
    "# scoring\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score, accuracy_score\n",
    "\n",
    "# my stuff\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from src.config import azure_language_endpoint, azure_language_key, azure_language_deployment, azure_language_project, data_path_rvm, out_folder\n",
    "from src.prepare_data import create_train_test_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973edafc-d9aa-47d8-be7a-9b39b8e4c04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_class(x):\n",
    "    # class categories for the language service must not contain special characters\n",
    "    # and must be less than 50 characters\n",
    "    return x.replace(':','').replace('/','')[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57a2a73-59d7-4259-ba70-9855f8f2e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in a list of documents to classify\n",
    "df = pd.read_excel(data_path_rvm, sheet_name = 'Q07a')\n",
    "df = df.iloc[:, 4:-1]\n",
    "\n",
    "# rename columns\n",
    "df.columns = ['Response'] + [clean_class(x) for x in list(df.columns[1:])]\n",
    "\n",
    "# remove multi-line characters and NA responses\n",
    "df = df[~pd.isna(df['Response'])]\n",
    "df['Response'] = df['Response'].apply(lambda x: x.replace('\\n',' '))\n",
    "# map categories to 0/1 instead of NaN/X\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:].map(lambda x: 1 if x=='X' else 0)\n",
    "\n",
    "# create None category\n",
    "df['None'] = df.apply(lambda row: 1 if sum(row[1:])==0 else 0, axis=1)\n",
    "\n",
    "# create a column flagging if this was held back as test data or not \n",
    "df['test_flag'] = False\n",
    "df.loc[df.index>=1000, 'test_flag'] = True\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c4663-f2f4-4102-a9b6-734c53a72ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of documents that can be sent to the endpoint \n",
    "documents = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    text = row.Response\n",
    "    documents.append(\n",
    "        {'id': idx, 'language': 'en-us', 'text': text}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385c589-998a-4365-ab13-056cb77ab597",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test on small number first\n",
    "documents_test = documents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd7e86d-f72b-451d-86c4-8d06746dd105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# submit classification request\n",
    "api_version = \"2022-05-01\"\n",
    "post_url = f\"{azure_language_endpoint}/language/analyze-text/jobs?api-version={api_version}\"\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Ocp-Apim-Subscription-Key\": azure_language_key\n",
    "}\n",
    "\n",
    "# can only request 25 at a time (maybe there's a batch endpoint to use somewhere?)\n",
    "# but for some reason I don't follow it only returns 20, so ... that's weird. \n",
    "i_start = 0\n",
    "i_end = 20\n",
    "\n",
    "# initialize empty \n",
    "df_out = pd.DataFrame(columns=df.columns[1:-1])\n",
    "\n",
    "# loop over all batches \n",
    "while i_start < len(documents):\n",
    "    print(f'Retrieving Documents {i_start} - {i_end}')\n",
    "    document_batch = documents[i_start: i_end]\n",
    "    payload = {\n",
    "        \"displayName\": \"Multi Label Classification Job\",\n",
    "        \"analysisInput\": {\"documents\": document_batch},\n",
    "        \"tasks\": [\n",
    "            {\n",
    "                \"kind\": \"CustomMultiLabelClassification\",\n",
    "                \"taskName\": \"Multi Label Classification\",\n",
    "                \"parameters\": {\n",
    "                    \"projectName\": azure_language_project,\n",
    "                    \"deploymentName\": azure_language_deployment\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    response = requests.post(post_url, headers=headers, json=payload)\n",
    "    \n",
    "    if response.status_code != 202:\n",
    "        print(f\"Error: {response.status_code}, {response.text}\")\n",
    "    \n",
    "    # Extract result URL from response\n",
    "    result_url = response.headers.get(\"Operation-Location\")\n",
    "    if not result_url:\n",
    "        print(\"Error: No operation URL returned.\")\n",
    "    \n",
    "    print(f\"Job submitted. Polling results at: {result_url}\")\n",
    "\n",
    "    # Poll for Results\n",
    "    while True:\n",
    "        result_response = requests.get(result_url, headers=headers)\n",
    "        result_json = result_response.json()\n",
    "    \n",
    "        status = result_json.get(\"status\", \"\").lower()\n",
    "        if status == \"succeeded\":\n",
    "            print(\"Job completed successfully!\")\n",
    "            break\n",
    "        elif status in [\"failed\", \"canceled\"]:\n",
    "            print(f\"Job failed: {result_json}\")\n",
    "            exit()\n",
    "        else:\n",
    "            print(f\"Job status: {status}. Waiting...\")\n",
    "            time.sleep(5)  # Wait before polling again\n",
    "\n",
    "    # Extract Results\n",
    "    classification_results = []\n",
    "    categories = list(df.columns[1:-1])\n",
    "    task = result_json.get(\"tasks\", [])\n",
    "    for doc in task['items'][0]['results']['documents']:\n",
    "        doc_id = doc[\"id\"]\n",
    "        cats = [x['category'] for x in doc['class']]\n",
    "        out_dict = {'id': doc_id}\n",
    "        for category in categories:\n",
    "            if category in cats:\n",
    "                out_dict[category] = 1\n",
    "            else:\n",
    "                out_dict[category] = 0\n",
    "        classification_results.append(out_dict)\n",
    "\n",
    "    df_out = pd.concat([df_out, pd.DataFrame(classification_results)])\n",
    "    i_start+=20\n",
    "    i_end+=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2cb360-71fc-4c04-bbd7-b37d55b66b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up ids\n",
    "df_out['id'] = df_out['id'].astype('int')\n",
    "df_out.index = df_out.id\n",
    "df_out.index.name = None\n",
    "#df_out.drop('id', axis=1, inplace=True)\n",
    "\n",
    "df_out['test_flag'] = False\n",
    "df_out.loc[df_out.index>=1000, 'test_flag'] = True\n",
    "\n",
    "df_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7be1116-baf3-47bd-99a3-26624e37745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to known outputs \n",
    "y = df[categories].values.astype('float')\n",
    "y_out = df_out[categories].values.astype('float')\n",
    "\n",
    "y_test = df[df.test_flag][categories].values.astype('float')\n",
    "y_out_test = df_out[df_out.test_flag][categories].values.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dc58e4-9b7d-4ae7-8584-60d90847016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get acc, f1, prec, recall\n",
    "extra = pd.DataFrame(\n",
    "    {'metric': ['acc', 'f1', 'prec', 'recall'], \n",
    "     'pct': [\n",
    "         accuracy_score(y, y_out),\n",
    "         f1_score(y, y_out, average='micro'),\n",
    "         precision_score(y, y_out, average='micro'),\n",
    "         recall_score(y, y_out, average='micro')\n",
    "     ],\n",
    "     'pct_test': [\n",
    "         accuracy_score(y_test, y_out_test),\n",
    "         f1_score(y_test, y_out_test, average='micro'),\n",
    "         precision_score(y_test, y_out_test, average='micro'),\n",
    "         recall_score(y_test, y_out_test, average='micro')\n",
    "     ]\n",
    "    }\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb17a8-b508-437d-8497-fd29cf508aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra.to_csv(out_folder+'/rbcm_q7_summary_language_service.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a853dcf-c6c6-4bc6-896c-45f9aa7a5fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
