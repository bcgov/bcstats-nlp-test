{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3332a62-074b-4914-bbb7-26c02f529b7c",
   "metadata": {},
   "source": [
    "Copyright 2025 Province of British Columbia\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1490a4d-2d13-4e13-823b-8b20a1693e4f",
   "metadata": {},
   "source": [
    "### Data Cleaning \n",
    "\n",
    "create a column that will work with AZ ML Workspace\n",
    "\n",
    "this was further updated to create a JSON file that works with the Language Studio service as well as producing the individual text files that are required for that service. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938952a9-d8a7-43bd-9cfb-9b2d9b7275ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system stuff\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# my stuff (abstracted non-important functions)\n",
    "# Get the project root (one level up from notebooks)\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "from src.config import data_path_rvm\n",
    "from src.prepare_data import create_train_test_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3971942f-4a8d-4a68-8c44-5faf84d859fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a single column to use as target for Azure\n",
    "def create_target(row):\n",
    "    options = row[1:]\n",
    "    # find where true\n",
    "    out = ','.join(['\"'+x+'\"' for x in options[options=='X'].index])\n",
    "    if len(out)==0:\n",
    "        out = '[\"Other\"]'\n",
    "    else:\n",
    "        out = '['+out+']'\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f696d88-7bcf-4d5c-9db8-f1dd5f9250a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(data_path_rvm, sheet_name = 'Q07a')\n",
    "df = df.iloc[:, 4:-1]\n",
    "df.columns = ['Response'] + list(df.columns[1:])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e12e4-cb79-45a2-ac66-8a2319293f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df.apply(create_target, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140c01f-8da9-46bc-8a7a-5b34c15f0318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove multi-line characters and NA responses\n",
    "df = df[~pd.isna(df['Response'])]\n",
    "df['Response'] = df['Response'].apply(lambda x: x.replace('\\n',' '))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1974de4-f5c2-4d94-a844-e9aa635d3399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split so that it only trains on a subset \n",
    "n_train = 1_000\n",
    "df_train, df_test = create_train_test_dataframes(df, n_train=n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344abb8-c186-4f7e-aa2d-9f011e7da099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull another 1_000 for validation\n",
    "df_validate, df_test = create_train_test_dataframes(df_test, n_train=n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50c2f61-034d-4cc0-aa6b-f25a4e4e9259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save these for upload to the workspace\n",
    "# after removing the int columns\n",
    "df_train[['Response', 'target']].to_csv(data_path_rvm.replace('.xlsx', '_train.csv'), index=False)\n",
    "df_validate[['Response', 'target']].to_csv(data_path_rvm.replace('.xlsx', '_validate.csv'), index=False)\n",
    "df_test[['Response', 'target']].to_csv(data_path_rvm.replace('.xlsx', '_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3e67b0-b7b8-4cd6-b0b7-931b00c7fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_class(x):\n",
    "    # class categories for the language service must not contain special characters\n",
    "    # and must be less than 50 characters\n",
    "    return x.replace(':','').replace('/','')[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29dffe1-0c1d-4488-9e63-71ecbd0861db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files for ai language service, as well as a json file that has all of the correct categories\n",
    "def get_classes_dict(row, outpath):\n",
    "    filename = f'text-{row.name:04d}.txt'\n",
    "    response = row['Response']\n",
    "    options = row[1:-1]\n",
    "    # find where true\n",
    "    out = [x for x in options[options=='X'].index]\n",
    "\n",
    "    if len(out) == 0:\n",
    "        out = ['None']\n",
    "    \n",
    "    doc_dict = {\n",
    "        'location': filename,\n",
    "        'language': 'en-us',\n",
    "        'classes': [{'category': clean_class(x)} for x in out]\n",
    "    }\n",
    "\n",
    "    # save file\n",
    "    with open(os.path.join(outpath, filename), 'w', encoding=\"utf-8\") as outfile:\n",
    "        outfile.write(response)\n",
    "\n",
    "    # return dictionary to append to json\n",
    "    return doc_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90b03c-56ff-4399-a693-6c1b6a4e9fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = os.path.join(os.path.dirname(data_path_rvm), 'language-ai')\n",
    "outpath_test = os.path.join(outpath, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7c9eaa-0c06-4054-b191-b941f38478ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    \"projectFileVersion\": \"2022-05-01\", # Don't change this date\n",
    "    \"stringIndexType\": \"Utf16CodeUnit\",\n",
    "    \"metadata\": {\n",
    "        \"projectKind\": \"CustomMultiLabelClassification\",\n",
    "        \"storageInputContainerName\": \"language-demo-lf\", # match to your container!\n",
    "        \"projectName\": \"language-demo-lf\", # match to your project!\n",
    "        \"multilingual\": 'false', # choose which matches your data\n",
    "        \"description\": \"Testing the RBCM data using the AI language service\",\n",
    "        \"language\": \"en\",\n",
    "        \"settings\": {}\n",
    "    },\n",
    "    'assets':{\n",
    "        \"projectKind\": \"CustomMultiLabelClassification\",\n",
    "        'classes':[{'category': clean_class(x)} for x in list(df_train.columns[1:-1]) + ['None']],\n",
    "        'documents': []\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d775a84-c0c3-4064-90ed-a04c4daee77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict['assets']['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2176b-9a4a-4373-ba4b-f3a786826f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all train files\n",
    "labels_train = labels_dict.copy()\n",
    "for ii, row in df_train.iterrows():\n",
    "    single_doc_dict = get_classes_dict(row, outpath)\n",
    "    labels_train['assets']['documents'].append(single_doc_dict)\n",
    "\n",
    "with open(os.path.join(outpath, 'rbcmLabels_v5.json'), 'w') as json_file:\n",
    "    json.dump(labels_train, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887fdf9-7ae4-4cd9-b1c6-9420d66d4c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all test files\n",
    "labels_test = labels_dict.copy()\n",
    "for ii, row in df_validate.iterrows():\n",
    "    single_doc_dict = get_classes_dict(row, outpath_test)\n",
    "    labels_test['assets']['documents'].append(single_doc_dict)\n",
    "\n",
    "with open(os.path.join(outpath_test, 'rbcmLabels_test.json'), 'w') as json_file:\n",
    "    json.dump(labels_test, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557cf6ca-8e1b-4816-acf6-0cd1517a31fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
